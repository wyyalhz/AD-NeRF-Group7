由于复现时遇到的50系显卡不能用pytorch3d的问题，加上老师发放了华为云代金券，于是决定尝试用华为云跑数据预处理。

## 1.创建私有云vpc和弹性服务器ecs

这个华为云上有官方教学实验，跟着做一遍就会了，每天有免费额度。b站也有类似视频，故这里直接跳过，自己根据需求选相应配置，记得选gpu加速型就行

## 2.vscode连接华为云服务器

接下来用vsc连接到华为云服务器。首先记得在“安全组”里放行22端口，选0.0.0.0/0（官网教学实验里也有讲）

然后在vsc中，确认安装remote-ssh插件，ctrl+shift+p输入并选择remote-ssh:add new host，输入root@华为云的弹性公网ip，enter输入密码enter，看到成功提示就连上了

接着就能从file里打开云端的文件夹，进入后创建project/，创建ssh密钥添加到github设置中，然后git clone项目仓库，具体指令直接问ai吧

## 3.

大体与wsl中安装环境步骤一致，有些额外的点：

### 3.1 上传/下载文件

在本地power shell中，可以用scp，也可以用sftp

```bash
sftp -P 22 root@122.9.44.152
put "E:\BIT\a3Junior\SpeechRecognitionAndSynthesis\deepspeech-0_1_0-b90017e8.pb\deepspeech-0_1_0-b90017e8.pb" /root/.tensorflow/models/
bye

scp -P 22 "E:\BIT\a3Junior\SpeechRecognitionAndSynthesis\deepspeech-0_1_0-b90017e8.pb\deepspeech-0_1_0-b90017e8.pb" root@122.9.44.152:/root/.tensorflow/models/

scp -P 22 "E:\BIT\a3Junior\SpeechRecognitionAndSynthesis\BaselFaceModel\PublicMM1\01_MorphableModel.mat" root@122.9.44.152:/root/projects/Reproduce-of-AD-NeRF/data_util/face_tracking/3DMM/

tar -czvf Lieu.tar.gz dataset/Lieu

scp -P 22 root@122.9.44.152:/root/projects/Reproduce-of-AD-NeRF/Lieu.tar.gz "E:\BIT\a3Junior\SpeechRecognitionAndSynthesis\"
```

### 3.2 更新nvidia驱动

[华为云更新驱动官方帮助](https://support.huaweicloud.com/usermanual-ecs/ecs_03_0199.html)

安装pytorch

```bash
pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://mirrors.aliyun.com/pytorch-wheels/cu124/ --extra-index-url https://pypi.tuna.tsinghua.edu.cn/simple
```

### 3.3 清华源

-i https://pypi.tuna.tsinghua.edu.cn/simple

### 3.4 安装ffmpeg

```bash
conda install -y -c conda-forge ffmpeg
```

### 3.5

用上gpu以后，在step6里，pred_img 多半是 GPU 上渲染/网络输出的，gt_img 或 img_mask 是从图片/np 读进来的，默认在 CPU，于是直接炸。最省事、最稳的修法：在 cal_col_loss() 里强制把 gt_img 和 img_mask 搬到 pred_img 的 device（让输出说了算）

打开：data_util/face_tracking/util.py，找到 cal_col_loss，在计算 loss 之前加几行：

```python
    # --- add these lines ---
    device = pred_img.device
    dtype = pred_img.dtype

    if not torch.is_tensor(gt_img):
        gt_img = torch.from_numpy(gt_img)
    if not torch.is_tensor(img_mask):
        img_mask = torch.from_numpy(img_mask)

    gt_img = gt_img.to(device=device, dtype=dtype)
    img_mask = img_mask.to(device=device, dtype=dtype)
    # -----------------------

    loss = torch.sqrt(torch.sum(torch.square(pred_img - gt_img), 3)) * img_mask / 255.0
    return loss
```

face_tracker.py里343行改成

```python
    # render_proj[mask] = render_imgs[mask][..., :3].byte() 原来的
    render_imgs_cpu = render_imgs.detach().cpu()
    mask_cpu = mask.detach().cpu() if torch.is_tensor(mask) else torch.from_numpy(mask).cpu()
    render_proj = render_proj.cpu()

    render_proj[mask_cpu] = render_imgs_cpu[mask_cpu][..., :3].to(torch.uint8)
```